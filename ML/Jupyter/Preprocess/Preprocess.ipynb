{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef8fb3-e344-4053-a754-21ccfbd58c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_datareader as web\n",
    "import datetime as dt\n",
    "import pandas_ta as ta\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c28f699-d763-45b9-94d8-2db63313c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Datasets/bitfinex_ETHUSDT1h.csv')\n",
    "data['date'] = pd.to_datetime(data['date'], unit='ms')\n",
    "date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e0c2f-99e5-4f6c-8eea-828f104ece17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data['date'],utc=True)\n",
    "data.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b96e219-48fc-4476-a529-95f6b5df6909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_709495/420165420.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"day\"] = temp_df.date.dt.day\n",
      "/tmp/ipykernel_709495/420165420.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"month\"] = temp_df.date.dt.month\n",
      "/tmp/ipykernel_709495/420165420.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"year\"] = temp_df.date.dt.year\n",
      "/tmp/ipykernel_709495/420165420.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"day\"] = temp_df.date.dt.day\n",
      "/tmp/ipykernel_709495/420165420.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"month\"] = temp_df.date.dt.month\n",
      "/tmp/ipykernel_709495/420165420.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"year\"] = temp_df.date.dt.year\n",
      "/tmp/ipykernel_709495/420165420.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"day\"] = temp_df.date.dt.day\n",
      "/tmp/ipykernel_709495/420165420.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"month\"] = temp_df.date.dt.month\n",
      "/tmp/ipykernel_709495/420165420.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"year\"] = temp_df.date.dt.year\n",
      "/tmp/ipykernel_709495/420165420.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"day\"] = temp_df.date.dt.day\n",
      "/tmp/ipykernel_709495/420165420.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"month\"] = temp_df.date.dt.month\n",
      "/tmp/ipykernel_709495/420165420.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"year\"] = temp_df.date.dt.year\n",
      "/tmp/ipykernel_709495/420165420.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"day\"] = temp_df.date.dt.day\n",
      "/tmp/ipykernel_709495/420165420.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"month\"] = temp_df.date.dt.month\n",
      "/tmp/ipykernel_709495/420165420.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"year\"] = temp_df.date.dt.year\n",
      "/tmp/ipykernel_709495/420165420.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"day\"] = temp_df.date.dt.day\n",
      "/tmp/ipykernel_709495/420165420.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"month\"] = temp_df.date.dt.month\n",
      "/tmp/ipykernel_709495/420165420.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"year\"] = temp_df.date.dt.year\n",
      "/tmp/ipykernel_709495/420165420.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"day\"] = temp_df.date.dt.day\n",
      "/tmp/ipykernel_709495/420165420.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"month\"] = temp_df.date.dt.month\n",
      "/tmp/ipykernel_709495/420165420.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"year\"] = temp_df.date.dt.year\n",
      "/tmp/ipykernel_709495/420165420.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"day\"] = temp_df.date.dt.day\n",
      "/tmp/ipykernel_709495/420165420.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"month\"] = temp_df.date.dt.month\n",
      "/tmp/ipykernel_709495/420165420.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"year\"] = temp_df.date.dt.year\n",
      "/tmp/ipykernel_709495/420165420.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"day\"] = temp_df.date.dt.day\n",
      "/tmp/ipykernel_709495/420165420.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"month\"] = temp_df.date.dt.month\n",
      "/tmp/ipykernel_709495/420165420.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"year\"] = temp_df.date.dt.year\n",
      "/tmp/ipykernel_709495/420165420.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"day\"] = temp_df.date.dt.day\n",
      "/tmp/ipykernel_709495/420165420.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"month\"] = temp_df.date.dt.month\n",
      "/tmp/ipykernel_709495/420165420.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"year\"] = temp_df.date.dt.year\n",
      "/tmp/ipykernel_709495/420165420.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"day\"] = temp_df.date.dt.day\n",
      "/tmp/ipykernel_709495/420165420.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"month\"] = temp_df.date.dt.month\n",
      "/tmp/ipykernel_709495/420165420.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df[\"year\"] = temp_df.date.dt.year\n"
     ]
    }
   ],
   "source": [
    "array = [[1,'W'],[1,'D'],[12,'h'],[6,'h'],[4,'h'],[3,'h'],[1,'h'],[30,'m'],[15,'m'],[5,'m'],[1,'m']]\n",
    "\n",
    "for number, unit in array:\n",
    "   \n",
    "\n",
    "\n",
    "    data = pd.read_csv( 'ETHUSDT-'+str(number) + unit + '-bitfinex.csv')\n",
    "    data['date'] = pd.to_datetime(data['date'],utc=True)\n",
    "    saeid = convert_date(data[['date','close']])\n",
    "    saeid.to_csv('../Datasets/converted_date_ETHUSDT-'+str(number) + unit + '-bitfinex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72cf15-aaf5-48e1-ae3c-9f3b7d265c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(temp_df: pd.DataFrame):\n",
    "    \n",
    "   \n",
    "    temp_df[\"day\"] = temp_df.date.dt.day\n",
    "    temp_df[\"month\"] = temp_df.date.dt.month\n",
    "    temp_df[\"year\"] = temp_df.date.dt.year\n",
    "    temp_df[\"hour\"] = temp_df.date.dt.hour\n",
    "    temp_df[\"day_of_week\"] = temp_df.date.dt.dayofweek\n",
    "    temp_df[\"season\"] = temp_df[\"month\"].apply(lambda x: int((((x + 1) % 12) - (((x + 1) % 12) % 3)) / 3))\n",
    "    encoder = OneHotEncoder()\n",
    "    season_one_hot_encode = encoder.fit_transform(temp_df[\"season\"].to_numpy().reshape(-1, 1)).toarray()\n",
    "    seasons_df = pd.DataFrame(season_one_hot_encode, columns=[\"winter\", \"spring\", \"summer\", \"fall\"])\n",
    "    temp_df = temp_df.join(seasons_df)\n",
    "    temp_df = temp_df.drop(columns=[\"season\"])\n",
    "    selected_columns = [\"day\", \"month\", \"hour\", \"day_of_week\"]\n",
    "    for column in selected_columns:\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        temp_df[column] = scaler.fit_transform(temp_df[column].to_numpy().reshape(-1, 1)) * np.pi\n",
    "        temp_df[column + \"_x\"] = np.sin(temp_df[column])\n",
    "        temp_df[column + \"_y\"] = np.cos(temp_df[column])\n",
    "\n",
    "    # temp_df = temp_df.drop(columns=selected_columns + [\"date\"])\n",
    "    temp_df = temp_df.drop(columns=selected_columns)\n",
    "\n",
    "    return temp_df\n",
    "\n",
    "\n",
    "\n",
    "def add_basic_macds(data : pd.DataFrame):\n",
    "    \n",
    "    data['hl2'] = (ta.hl2(high=data['high'], low=data['low'])).values\n",
    "    data['hlc3'] = (ta.hlc3(high=data['high'], low=data['low'], close=data['close'])).values\n",
    "    data['ohlc4'] = (ta.ohlc4(high=data['high'], low=data['low'], close=data['close'],open_=data['open'])).values\n",
    "\n",
    "    korosh = ta.macd(data['hl2'])\n",
    "    data['hl2_MD'] = korosh['MACD_12_26_9']\n",
    "    data['hl2_MDh'] = korosh['MACDh_12_26_9']\n",
    "    data['hl2_MDs'] = korosh['MACDs_12_26_9']\n",
    "\n",
    "\n",
    "    korosh = ta.macd(data['hlc3'])\n",
    "    data['hlc3_MD'] = korosh['MACD_12_26_9']\n",
    "    data['hlc3_MDh'] = korosh['MACDh_12_26_9']\n",
    "    data['hlc3_MDs'] = korosh['MACDs_12_26_9']\n",
    "\n",
    "\n",
    "\n",
    "    korosh = ta.macd(data['ohlc4'])\n",
    "    data['ohlc4_MD'] = korosh['MACD_12_26_9']\n",
    "    data['ohlc4_MDh'] = korosh['MACDh_12_26_9']\n",
    "    data['ohlc4_MDs'] = korosh['MACDs_12_26_9']\n",
    "    return data\n",
    "\n",
    "\n",
    "def add_all_macds_by_arman( data : pd.DataFrame ):\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    import pandas as pd\n",
    "    import pandas_ta as ta\n",
    "    import time\n",
    "    from tqdm import tqdm\n",
    "    from functools import partial\n",
    "    from dateutil import parser\n",
    "    from multiprocessing import Pool\n",
    "    import multiprocessing\n",
    "    from multiprocessing import Process, Lock\n",
    "\n",
    "    from pandas import concat, DataFrame\n",
    "    from pandas_ta import wma\n",
    "    from pandas_ta.overlap import ema, sma\n",
    "    from pandas_ta.utils import get_offset, verify_series, signals\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def macd_indicator(close, fast=None, slow=None, signal=None, talib=None, offset=None, matype=None, **kwargs):\n",
    "        \"\"\"Indicator: Moving Average, Convergence/Divergence (MACD)\"\"\"\n",
    "        # Validate arguments\n",
    "        fast = int(fast) if fast and fast > 0 else 12\n",
    "        slow = int(slow) if slow and slow > 0 else 26\n",
    "        signal = int(signal) if signal and signal > 0 else 9\n",
    "        if slow < fast:\n",
    "            fast, slow = slow, fast\n",
    "        close = verify_series(close, max(fast, slow, signal))\n",
    "        offset = get_offset(offset)\n",
    "        mode_tal = bool(talib) if isinstance(talib, bool) else True\n",
    "\n",
    "        if close is None: return\n",
    "\n",
    "        as_mode = kwargs.setdefault(\"asmode\", False)\n",
    "\n",
    "        # Calculate Result\n",
    "\n",
    "        if matype == \"ema\" or matype is None:\n",
    "            fastma = ema(close, length=fast)\n",
    "            slowma = ema(close, length=slow)\n",
    "\n",
    "            macd = fastma - slowma\n",
    "            signalma = ema(close=macd.loc[macd.first_valid_index():, ], length=signal)\n",
    "            histogram = macd - signalma\n",
    "        elif matype == \"sma\":\n",
    "            fastma = sma(close, length=fast)\n",
    "            slowma = sma(close, length=slow)\n",
    "\n",
    "            macd = fastma - slowma\n",
    "            signalma = sma(close=macd.loc[macd.first_valid_index():, ], length=signal)\n",
    "            histogram = macd - signalma\n",
    "        elif matype == \"wma\":\n",
    "            fastma = wma(close, length=fast)\n",
    "            slowma = wma(close, length=slow)\n",
    "\n",
    "            macd = fastma - slowma\n",
    "            signalma = wma(close=macd.loc[macd.first_valid_index():, ], length=signal)\n",
    "            histogram = macd - signalma\n",
    "\n",
    "        if as_mode:\n",
    "            if matype == \"ema\" or matype is None:\n",
    "                macd = macd - signalma\n",
    "                signalma = ema(close=macd.loc[macd.first_valid_index():, ], length=signal)\n",
    "                histogram = macd - signalma\n",
    "            elif matype == \"sma\":\n",
    "                macd = macd - signalma\n",
    "                signalma = sma(close=macd.loc[macd.first_valid_index():, ], length=signal)\n",
    "                histogram = macd - signalma\n",
    "            elif matype == \"wma\":\n",
    "                macd = macd - signalma\n",
    "                signalma = wma(close=macd.loc[macd.first_valid_index():, ], length=signal)\n",
    "                histogram = macd - signalma\n",
    "\n",
    "        # Offset\n",
    "        if offset != 0:\n",
    "            macd = macd.shift(offset)\n",
    "            histogram = histogram.shift(offset)\n",
    "            signalma = signalma.shift(offset)\n",
    "\n",
    "        # Handle fills\n",
    "        if \"fillna\" in kwargs:\n",
    "            macd.fillna(kwargs[\"fillna\"], inplace=True)\n",
    "            histogram.fillna(kwargs[\"fillna\"], inplace=True)\n",
    "            signalma.fillna(kwargs[\"fillna\"], inplace=True)\n",
    "        if \"fill_method\" in kwargs:\n",
    "            macd.fillna(method=kwargs[\"fill_method\"], inplace=True)\n",
    "            histogram.fillna(method=kwargs[\"fill_method\"], inplace=True)\n",
    "            signalma.fillna(method=kwargs[\"fill_method\"], inplace=True)\n",
    "\n",
    "        # Name and Categorize it\n",
    "        _asmode = \"AS\" if as_mode else \"\"\n",
    "        _props = f\"_{fast}_{slow}_{signal}\"\n",
    "        macd.name = f\"MACD{_asmode}{_props}\"\n",
    "        histogram.name = f\"MACD{_asmode}h{_props}\"\n",
    "        signalma.name = f\"MACD{_asmode}s{_props}\"\n",
    "        macd.category = histogram.category = signalma.category = \"momentum\"\n",
    "\n",
    "        # Prepare DataFrame to return\n",
    "        data = {macd.name: macd, histogram.name: histogram, signalma.name: signalma}\n",
    "        df = DataFrame(data)\n",
    "        df.name = f\"MACD{_asmode}{_props}\"\n",
    "        df.category = macd.category\n",
    "\n",
    "        signal_indicators = kwargs.pop(\"signal_indicators\", False)\n",
    "        if signal_indicators:\n",
    "            signalsdf = concat(\n",
    "                [\n",
    "                    df,\n",
    "                    signals(\n",
    "                        indicator=histogram,\n",
    "                        xa=kwargs.pop(\"xa\", 0),\n",
    "                        xb=kwargs.pop(\"xb\", None),\n",
    "                        xserie=kwargs.pop(\"xserie\", None),\n",
    "                        xserie_a=kwargs.pop(\"xserie_a\", None),\n",
    "                        xserie_b=kwargs.pop(\"xserie_b\", None),\n",
    "                        cross_values=kwargs.pop(\"cross_values\", True),\n",
    "                        cross_series=kwargs.pop(\"cross_series\", True),\n",
    "                        offset=offset,\n",
    "                    ),\n",
    "                    signals(\n",
    "                        indicator=macd,\n",
    "                        xa=kwargs.pop(\"xa\", 0),\n",
    "                        xb=kwargs.pop(\"xb\", None),\n",
    "                        xserie=kwargs.pop(\"xserie\", None),\n",
    "                        xserie_a=kwargs.pop(\"xserie_a\", None),\n",
    "                        xserie_b=kwargs.pop(\"xserie_b\", None),\n",
    "                        cross_values=kwargs.pop(\"cross_values\", False),\n",
    "                        cross_series=kwargs.pop(\"cross_series\", True),\n",
    "                        offset=offset,\n",
    "                    ),\n",
    "                ],\n",
    "                axis=1,\n",
    "            )\n",
    "\n",
    "            return signalsdf\n",
    "        else:\n",
    "            return df\n",
    "\n",
    "        \n",
    "    def get_indicator_elements(indicator: str):\n",
    "        if indicator == \"rsi\":\n",
    "            rsi_range = [['period', 5, 25],\n",
    "                         ['overbuy', 60, 100],\n",
    "                         ['oversell', 0, 40],\n",
    "                         ['source', 'low', 'high', 'close', 'open', 'hlc2', 'hlc3', 'ohlc4']\n",
    "                         ]\n",
    "            return get_elements(rsi_range, setting_size=4)\n",
    "        if indicator == \"macd\":\n",
    "            macd_range = [['fast', 5, 12],\n",
    "                          ['slow', 11, 20],\n",
    "                          ['signal', 22, 48],\n",
    "                          ['source', 'low', 'high', 'close', 'open', 'hlc2', 'hlc3', 'ohlc4'],\n",
    "                          ['MA', 'ema', 'sma', 'wma']\n",
    "                          ]\n",
    "            return get_elements(macd_range, setting_size=5)\n",
    "        if indicator == \"stochrsi\":\n",
    "            stochrsi_range = [['k', 3, 5],\n",
    "                              ['d', 3, 5],\n",
    "                              ['length', 50, 57],\n",
    "                              ['rsi_length', 50, 57],\n",
    "                              ['source', 'low', 'high', 'close', 'open', 'hlc2', 'hlc3', 'ohlc4'],\n",
    "                              ['overbuy', 70, 100],\n",
    "                              ['oversell', 0, 30]\n",
    "                              ]\n",
    "            return get_elements(stochrsi_range, setting_size=7)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_source(data: pd.DataFrame, source: str = 'close'):\n",
    "\n",
    "\n",
    "        saeid = {\n",
    "            'hl2': data.ta.hl2(),\n",
    "            'hlc3': data.ta.hlc3(),\n",
    "            'ohlc4': data.ta.ohlc4(),\n",
    "            'close': data['close'],\n",
    "            'high': data['high'],\n",
    "            'low': data['low'],\n",
    "            'open': data['open']\n",
    "        }.get(source, data['close'])\n",
    "\n",
    "        return saeid\n",
    "\n",
    "\n",
    "    def get_elements(test, setting_size: int):\n",
    "        adad = []\n",
    "        for i in range(len(test)):\n",
    "            if isinstance(test[i][1], int):\n",
    "                adad.append(np.arange(test[i][1], test[i][2] + 1, 1).tolist())\n",
    "            elif isinstance(test[i][1], str):\n",
    "                adad.append((test[i])[1:])\n",
    "\n",
    "      \n",
    "        if setting_size == 4:\n",
    "            elements = []\n",
    "            for element in itertools.product(adad[0], adad[1], adad[2], adad[3]):\n",
    "                elements.append(list(element))\n",
    "            return elements\n",
    "        if setting_size == 5:\n",
    "            elements = []\n",
    "            for element in itertools.product(adad[0], adad[1], adad[2], adad[3], adad[4]):\n",
    "                elements.append(list(element))\n",
    "            return elements\n",
    "        if setting_size == 7:\n",
    "            elements = []\n",
    "            for element in itertools.product(adad[0], adad[1], adad[2], adad[3], adad[4], adad[5], adad[6]):\n",
    "                elements.append(list(element))\n",
    "            return elements\n",
    "\n",
    "    def correlation(dataset, threshold):\n",
    "        col_corr = set()  # Set of all the names of correlated columns\n",
    "        corr_matrix = dataset.corr()\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i):\n",
    "                if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                    colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                    col_corr.add(colname)\n",
    "        return col_corr\n",
    "    def create_macds(obj , dataset):\n",
    "        macd = macd_indicator(close=get_source(data = data, source=obj[3]), fast=obj[0],\n",
    "                          slow=obj[1],\n",
    "                          signal=obj[2],\n",
    "                          matype=obj[4])\n",
    "\n",
    "        macd = macd.drop(macd.columns[1] , axis=1)\n",
    "        macd.columns = [macd.columns[0]+\"\"+obj[3]+\"\"+obj[4] , macd.columns[1]+\"\"+obj[3]+\"\"+obj[4]]\n",
    "        return macd\n",
    "\n",
    "\n",
    "    from tqdm.contrib.concurrent import thread_map , process_map\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    remove = ['open','high','low','close','volume']\n",
    "    elements = get_indicator_elements('macd')\n",
    "\n",
    "    feature_data = data.copy(deep=True)\n",
    "    feature_data = feature_data.drop(['date'] , axis =1)\n",
    "\n",
    "    step = 300\n",
    "    for i in tqdm(range(0,len(elements),step)):\n",
    "        if (i+step) >= len(elements) :\n",
    "\n",
    "            sub_elements = elements[i:]\n",
    "        else:\n",
    "\n",
    "            sub_elements = elements[i:i+step]\n",
    "\n",
    "\n",
    "        pool = Pool(12)\n",
    "\n",
    "        r_macd = partial(create_macds, dataset=data.copy(deep=True))\n",
    "        start_time = time.time()\n",
    "        f = process_map(r_macd, sub_elements)\n",
    "        df = pd.concat(f , axis=1)\n",
    "        print(np.shape(feature_data))\n",
    "\n",
    "        for i in(df.columns):\n",
    "\n",
    "            if (df[i] == 0).any():\n",
    "                if (df[i].value_counts())[0] > 1000:\n",
    "                    df = df.drop(i,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        frames = [feature_data, df]\n",
    "        feature_data = pd.concat(frames , axis = 1 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        corr_features = correlation(feature_data, 0.85)\n",
    "\n",
    "\n",
    "        for i in remove:\n",
    "\n",
    "            if i in corr_features:\n",
    "                corr_features.remove(i)\n",
    "\n",
    "        feature_data = feature_data.drop(corr_features,axis=1)\n",
    "    return feature_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe4194-e8ea-4edd-acc8-cdfd73cedbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mr.Kataei 8/4/2021\n",
    "get_candle_api use in stream to get candles for analysis and strategies this method have limit for n last candles\n",
    "you need for analysis.data collect form Bitfinex API where url can change for any API you want.\n",
    "there is 3 type of dictionary for bitfinex symbols or CSvs we need to save\n",
    "_get_all_candles is private method to use in generate_big_data where collect all data that can get from bitfinex\n",
    "\"\"\"\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import enum\n",
    "\n",
    "\n",
    "class Exchange(enum.Enum):\n",
    "    binance = 'binance'\n",
    "    bitfinex = 'bitfinex'\n",
    "\n",
    "\n",
    "class Symbols(enum.Enum):\n",
    "    BTCUSDT = 'bitcoin'\n",
    "    ETHUSDT = 'ethereum'\n",
    "    ADAUSDT = 'cardano'\n",
    "    DOGEUSDT = 'doge'\n",
    "    BCHUSDT = 'bitcoinCash'\n",
    "    ETCUSDT = 'ethereumClassic'\n",
    "\n",
    "\n",
    "symbols = {'BTCUSDT', 'ETHUSDT', 'ADAUSDT', 'DOGEUSDT', 'BCHUSDT', 'ETCUSDT'}\n",
    "\n",
    "symbols_bitfinix = {'BTCUSDT': 'tBTCUSD', 'ETHUSDT': 'tETHUSD', 'ADAUSDT': 'tADAUSD', 'DOGEUSDT': 'tDOGE:USD',\n",
    "                    'BCHUSDT': 'tBCHN:USD', 'ETCUSDT': 'tETCUSD'}\n",
    "\n",
    "\n",
    "def get_url_params_column(exchange: Exchange, timeframe: str, symbol: str, start_time: int = 115133520000):\n",
    "    # 115133520000 is Wednesday, 21 December 2005 02:52:00\n",
    "    if exchange.name == Exchange.binance.name:\n",
    "        params = {'interval': timeframe, 'symbol': symbol, 'limit': 1000, 'startTime': start_time}\n",
    "        url = 'https://api1.binance.com/api/v3/klines'\n",
    "        columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'Qav', 'trade-number', 'TBbav',\n",
    "                   'TBbqv', 'ignore']\n",
    "    elif exchange.name == Exchange.bitfinex.name:\n",
    "        symbol = symbols_bitfinix[symbol]\n",
    "        params = {'limit': 10000, 'sort': 1, 'start': start_time}\n",
    "        url = f'https://api-pub.bitfinex.com/v2/candles/trade:{timeframe}:{symbol}/hist'\n",
    "        columns = ['date', 'open', 'close', 'high', 'low', 'volume']\n",
    "    else:\n",
    "        return\n",
    "    return params, url, columns\n",
    "\n",
    "\n",
    "def calculate_end_time(number: int = 4, unit: str = 'h'):\n",
    "    convert_time_to_ms = 0\n",
    "    if unit == 'h':\n",
    "        convert_time_to_ms = 3600 * 1000\n",
    "    elif unit == 'm':\n",
    "        convert_time_to_ms = 60 * 1000\n",
    "    elif unit == 'd':\n",
    "        convert_time_to_ms = 3600 * 1000 * 24\n",
    "\n",
    "    end_time = int(round(time.time() * 1000))\n",
    "    return end_time - number * convert_time_to_ms\n",
    "\n",
    "\n",
    "def get_all_candles_binance(exchange: Exchange, symbol: Symbols, number: int = 4, unit: str = 'h',\n",
    "                            is_tehran: bool = True, save_csv: bool = True):\n",
    "    \"\"\"\n",
    "    :param exchange: its enum from Exchange ( bitfinex , binance ,...)\n",
    "    :param symbol: its enum from Symbols\n",
    "    :param number: its int number number of day or hours or minutes\n",
    "    :param unit: its string for which timeframe,  m for minutes , h for hours , d for day\n",
    "    :param is_tehran: for casting to tehran time this parameter need to be true\n",
    "    :param save_csv:  for save data to directory calls this function needs to be true\n",
    "    :return: dataframe of ohcl\n",
    "    \"\"\"\n",
    "    timeframe = str(number) + unit\n",
    "    symbol = symbol.name\n",
    "    params, url, columns = get_url_params_column(exchange=exchange, timeframe=timeframe, symbol=symbol)\n",
    "    if params is None:\n",
    "        return\n",
    "\n",
    "    end_time = calculate_end_time(number=number, unit=unit)\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url=url, params=params)\n",
    "        data = r.json()\n",
    "        data = pd.DataFrame(data=data, columns=columns).astype(float)\n",
    "        data = data[data.columns[:]]\n",
    "        start_time = int(data.tail(1)['date'].values[0])\n",
    "        while start_time < end_time:\n",
    "            params, url, columns = get_url_params_column(exchange=exchange, timeframe=timeframe, symbol=symbol,\n",
    "                                                         start_time=start_time)\n",
    "            r = requests.get(url=url, params=params)\n",
    "            next_data = r.json()\n",
    "            next_data = pd.DataFrame(data=next_data, columns=columns).astype(float)\n",
    "            next_data = next_data[data.columns[:]]\n",
    "            data = pd.concat([data, next_data], axis=0)\n",
    "            data = data.reset_index(drop=True)\n",
    "            start_time = int(data.tail(1)['date'].values[0])\n",
    "        if is_tehran:\n",
    "            data.date = pd.DatetimeIndex(pd.to_datetime(data['date'], unit='ms', yearfirst=True)).tz_localize(\n",
    "                'UTC').tz_convert('Asia/Tehran')\n",
    "        data = data.drop_duplicates(subset=['date'])\n",
    "        if save_csv:\n",
    "            data.to_csv(f'{symbol}-{timeframe}-{exchange.name}.csv', index=False)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f'something wrong on get data from {exchange.name}:\\n', e)\n",
    "\n",
    "\n",
    "def get_candle_bitfinex(symbol: str, timeframe: str, limit: int):\n",
    "    symbol = symbols_bitfinix[symbol]\n",
    "    params = {'limit': limit, 'sort': -1}\n",
    "    url = f'https://api-pub.bitfinex.com/v2/candles/trade:{timeframe}:{symbol}/hist'\n",
    "    try:\n",
    "        r = requests.get(url=url, params=params)\n",
    "        data = r.json()\n",
    "        data = pd.DataFrame(data=data, columns=['date', 'open', 'close', 'high', 'low', 'volume'])\n",
    "        data.date = pd.DatetimeIndex(pd.to_datetime(data['date'], unit='ms', yearfirst=True)\n",
    "                                     ).tz_localize('UTC').tz_convert('Asia/Tehran')\n",
    "        data = data.iloc[::-1]\n",
    "        data = data.reset_index(drop=True)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print('something wrong on get data from bitfinex:\\n', e)\n",
    "\n",
    "\n",
    "def get_candle_binance(symbol: str, limit: int, number: int = 4, unit: str = 'h'):\n",
    "    timeframe = str(number) + unit\n",
    "    end_time = calculate_end_time(number=number, unit=unit)\n",
    "    params = {'interval': timeframe, 'symbol': symbol, 'limit': limit, 'endTime': end_time}\n",
    "    url = 'https://api1.binance.com/api/v3/klines'\n",
    "    try:\n",
    "        r = requests.get(url=url, params=params)\n",
    "        data = r.json()\n",
    "        data = pd.DataFrame(data=data, columns=['date', 'open', 'high', 'low', 'close', 'volume', 'close_time',\n",
    "                                                'Qav', 'trade-number', 'TBbav', 'TBbqv', 'ignore']).astype(float)\n",
    "        data = data[data.columns[0:6]]\n",
    "        data.date = pd.DatetimeIndex(pd.to_datetime(data['date'], unit='ms', yearfirst=True)).tz_localize(\n",
    "            'UTC').tz_convert(\n",
    "            'Asia/Tehran')\n",
    "        return True, data\n",
    "    except Exception as e:\n",
    "        result = 'something wrong getting data from binance:\\n' + str(e)\n",
    "        return False, result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f63e4e-25c5-4a0e-aad5-a7e5de02edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Mr.kataei 1/3/2022\n",
    "\"\"\"\n",
    "from Libraries.data_collector import *\n",
    "import pandas_ta as ta\n",
    "import pandas as pd\n",
    "\n",
    "exchange = Exchange.bitfinex\n",
    "symbol = Symbols.BTCUSDT\n",
    "\n",
    "\n",
    "\n",
    "def willr(dataframe: pd.DataFrame, length: int = 14):\n",
    "    try:\n",
    "        return ta.willr(high=dataframe['high'], low=dataframe['low'], close=dataframe['close'], length=length)\n",
    "    except Exception as e:\n",
    "        print(f'invalid dataframe: {e}')\n",
    "\n",
    "\n",
    "def cmo(dataframe: pd.DataFrame, length: int = 14, scalar: int = 100):\n",
    "    try:\n",
    "        return ta.cmo(close=dataframe['close'], length=length, scalar=scalar)\n",
    "    except Exception as e:\n",
    "        print(f'invalid dataframe: {e}')\n",
    "\n",
    "\n",
    "def mfi(dataframe: pd.DataFrame, length: int = 14):\n",
    "    try:\n",
    "        return ta.mfi(high=dataframe['high'], low=dataframe['low'], close=dataframe['close'],\n",
    "                      volume=dataframe['volume'], length=length)\n",
    "    except Exception as e:\n",
    "        print(f'invalid dataframe: {e}')\n",
    "\n",
    "\n",
    "def stochRsi(dataframe: pd.DataFrame, length: int = 14, rsi_length: int = 14, k: int = 3, d: int = 3):\n",
    "    try:\n",
    "        return ta.stochrsi(close=dataframe['close'], length=length, rsi_length=rsi_length, k=k, d=d)\n",
    "    except Exception as e:\n",
    "        print(f'invalid dataframe: {e}')\n",
    "\n",
    "\n",
    "def generate_dataset(dataframe: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    **need must functional in future**\n",
    "    :param dataframe: dataframe ohclv\n",
    "    :return: indicators with dataframe\n",
    "    \"\"\"\n",
    "    stoch_rsi_indicator = stochRsi(dataframe=dataframe)\n",
    "    mfi_indicator = mfi(dataframe=dataframe)\n",
    "    cmo_indicator = cmo(dataframe=dataframe)\n",
    "    willr_indicator = willr(dataframe=dataframe)\n",
    "\n",
    "    temp = pd.concat([stoch_rsi_indicator, mfi_indicator, cmo_indicator, willr_indicator], axis=1)\n",
    "    temp.columns = [\"stoch_k\", \"stoch_d\", \"mfi\", \"cmo\", \"willr\"]\n",
    "    dataframe = pd.concat([dataframe, temp], axis=1)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a748ccd-3d5a-4480-b761-020de92f82c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "saeid = convert_date(data[['date','close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde23b8-8d44-48d4-98d6-cf8ceac45ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "saeid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66e22d-43af-41be-9d83-7458cb299923",
   "metadata": {},
   "outputs": [],
   "source": [
    "saeid.to_csv('../converted_date_all_4h_ETHUSDT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62242bb1-d8a2-46f9-936e-9a45b4d0016a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f6a892-ca27-4ae1-a80e-dd8bbc9f1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_all_macds_by_arman(pd.read_csv('../ETHUSDT4h.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba3d2e-e49a-431b-b4a5-fdb2612c5199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
